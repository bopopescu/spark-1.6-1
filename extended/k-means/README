
---------------------------------------------
Author: Omid Mashayekhi <omidm@stanford.edu>
---------------------------------------------

K-means program, applying the k-means clustering  algorithm over a collection
of input samples. Samples are randomly generated but potentially you could
change the code to read in samples from input files.

After launching master and slaves use the spark-submit script as follows:
  
../../bin/spark-submit
      --conf spark.eventLog.enabled=true
      --conf spark.eventLog.dir=../../log-dir
      --class LogisticRegression
      --master spark://<master-url>:7077
      --deploy-mode client
      --executor-memory 4g
      target/scala-2.10/logistic-regression_2.10-1.0.jar
        <Int dimension>
        <Int cluster_num>
        <Int iteration_num>
        <Int partition_num>
        <Float sample_num in million>
        <Int spin_wait in micro seconds>
        <String "m" for two stages implementation, else single stage>

In the single satge mode, if the spin wait value is non-zero it replaces each
clustering calculation with a spin wait that last as long as the argument (in
micro seconds). The two stage case is independent of the spin wait value and
always compute clustering.


Makefile options:
    $ make                to build
    $ make start          start a master and slave locally
    $ make stop           stop master and slave locally
    $ make run            to run an example againt local master and slave
    $ make run-events     activate event logging as well
    $ make run-multiple   activate events and two stage implementation
    $ make clean          clean generated binary
    $ make clean-all      clean generated binary and also log directories


